{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4ef103-a75b-40a2-a7b0-efc64a5f3d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,cv2,keras\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from IPython import display\n",
    "\n",
    "import config\n",
    "from config import Config\n",
    "import util\n",
    "\n",
    "from keras.layers import Dense\n",
    "from keras import Model\n",
    "from keras import optimizers\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.utils import plot_model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from sklearn.preprocessing import LabelBinarizer\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800d0172-31d6-4db0-9146-cc6626c38504",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Setting Custom Configuration\n",
    "\"\"\"\n",
    "\n",
    "class WiderFaceConfig(Config):\n",
    "    \"\"\"Configuration for training on WIDER face dataset.\n",
    "    WiderFaceConfig classs derives from the base Config class and overrides configurations specific\n",
    "    to the WIDER Face dataset.\n",
    "    \"\"\"\n",
    "    NAME = \"wider_face_experiment1\"\n",
    "    WEIGHTS = \"imagenet\"\n",
    "    LEARNING_RATE = 0.0001\n",
    "    ROTATION_RANGE_IMAGEGEN = 90\n",
    "    DTYPE_IMAGEGEN = 'uint8'\n",
    "    MONITOR = 'val_loss'\n",
    "    SAVE_FREQ = 'epoch'\n",
    "    STEPS_PER_EPOCH = 10\n",
    "    TOTAL_EPOCHS = 1000\n",
    "    VALIDATION_STEPS = 2\n",
    "    NUM_CLASSES = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737c3345-0794-40ba-8444-dbd978094ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting image and annotation paths\n",
    "#image_path = \"WIDER FACE/WIDER_train/images\"\n",
    "#annot_path = \"WIDER FACE/wider_face_split\"\n",
    "\n",
    "image_path = \"../WIDER FACE/wider_subset_images/images\"\n",
    "annot_path = \"../WIDER FACE/wider_subset_images/annots\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0fe577d-51c2-4a4e-b7e9-a1e4516bdccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw rectangles on first image of the dataset using anotaions upto 9(<10)\n",
    "for e,i in enumerate(os.listdir(annot_path)):\n",
    "    if e < 21:\n",
    "        filename = i.split(\".\")[0]+\".jpg\"\n",
    "        print(filename)\n",
    "        img = cv2.imread(os.path.join(image_path,filename), cv2.IMREAD_ANYCOLOR)\n",
    "        df = pd.read_csv(os.path.join(annot_path,i), sep='\\t', names=['temp'])\n",
    "        #plt.imshow(img)\n",
    "        for row in df.iterrows():\n",
    "            x1 = int(row[1][0].split(\" \")[0])\n",
    "            y1 = int(row[1][0].split(\" \")[1])\n",
    "            x2 = int(row[1][0].split(\" \")[2])\n",
    "            y2 = int(row[1][0].split(\" \")[3])\n",
    "            cv2.rectangle(img,(x1,y1),(x2,y2),(255,0,0), 2)\n",
    "        plt.figure()\n",
    "        plt.imshow(img)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e595c3-bada-40ba-a7df-7cc509efd1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cv2.setUseOptimized(True);\n",
    "#ss = cv2.ximgproc.segmentation.createSelectiveSearchSegmentation()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5e3ec7-11ed-4f52-a875-43e15bcecb81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def selective_search(image_path, image_name):\n",
    "    \"\"\"\n",
    "    perform Fast Selective Search for the passed image\n",
    "    \"\"\"\n",
    "    \n",
    "    cv2.setUseOptimized(True)\n",
    "\n",
    "    img = cv2.imread(os.path.join(image_path, image_name))\n",
    "\n",
    "    ss = cv2.ximgproc.segmentation.createSelectiveSearchSegmentation()\n",
    "    ss.setBaseImage(img)\n",
    "    ss.switchToSelectiveSearchFast()\n",
    "    ssresults = ss.process()\n",
    "    \n",
    "    return ssresults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc277ce-f62d-4922-9811-4586b6fbe04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "im = cv2.imread(os.path.join(image_path,\"0.jpg\"))\n",
    "rects = selective_search(image_path,\"0.jpg\")\n",
    "imOut = im.copy()\n",
    "for i, rect in (enumerate(rects)):\n",
    "    x, y, w, h = rect\n",
    "#     print(x,y,w,h)\n",
    "#     imOut = imOut[x:x+w,y:y+h]\n",
    "    cv2.rectangle(imOut, (x, y), (x+w, y+h), (0, 255, 0), 1, cv2.LINE_AA)\n",
    "# plt.figure()\n",
    "plt.imshow(imOut)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e665e7-f6bf-44b7-bb1b-45259fabc1e7",
   "metadata": {},
   "source": [
    "# Image Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600ea807-34c3-4d89-9d9f-d5d4fc17f467",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images=[]\n",
    "train_labels=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ebd5a9a-0e8b-4e9e-89c3-f16df721ed03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cv2.setUseOptimized(True);\n",
    "#ss = cv2.ximgproc.segmentation.createSelectiveSearchSegmentation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd797832-ff6f-4fff-96a0-7878358a49f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for e,i in enumerate(os.listdir(annot_path)):\n",
    "    try:\n",
    "        #if i.startswith(\"airplane\"):\n",
    "            filename = i.split(\".\")[0]+\".jpg\"\n",
    "            print(e,filename)\n",
    "            image = cv2.imread(os.path.join(image_path,filename))\n",
    "            df = pd.read_csv(os.path.join(annot_path,i), sep='\\t', names=['temp'])\n",
    "            gtvalues=[] \n",
    "            for row in df.iterrows():\n",
    "                x1 = int(row[1][0].split(\" \")[0])\n",
    "                y1 = int(row[1][0].split(\" \")[1])\n",
    "                x2 = int(row[1][0].split(\" \")[2])\n",
    "                y2 = int(row[1][0].split(\" \")[3])\n",
    "                 # appending groundtruth values\n",
    "                gtvalues.append({\"x1\":x1,\"x2\":x2,\"y1\":y1,\"y2\":y2})\n",
    "            #ss.setBaseImage(image)\n",
    "            #ss.switchToSelectiveSearchFast()\n",
    "            #ssresults = ss.process()\n",
    "            ssresults = selective_search(image_path, filename)\n",
    "            imout = image.copy()\n",
    "            counter = 0\n",
    "            falsecounter = 0\n",
    "            flag = 0\n",
    "            fflag = 0\n",
    "            bflag = 0\n",
    "            for e,result in enumerate(ssresults):\n",
    "                if e < config.MAX_REGIONS and flag == 0:\n",
    "                    for gtval in gtvalues:\n",
    "                        x,y,w,h = result\n",
    "                        iou = util.calculate_iou(gtval,{\"x1\":x,\"x2\":x+w,\"y1\":y,\"y2\":y+h})\n",
    "                        if counter < 30:\n",
    "                            if iou > 0.70:\n",
    "                                timage = imout[y:y+h,x:x+w]\n",
    "                                resized = cv2.resize(timage, (config.IMAGE_MIN_DIM, config.IMAGE_MAX_DIM), interpolation = cv2.INTER_AREA)\n",
    "                                train_images.append(resized)\n",
    "                                train_labels.append(1)\n",
    "                                counter += 1\n",
    "                        else :\n",
    "                            fflag =1\n",
    "                        if falsecounter <30:\n",
    "                            if iou < 0.3:\n",
    "                                timage = imout[y:y+h,x:x+w]\n",
    "                                resized = cv2.resize(timage, (config.IMAGE_MIN_DIM,config.IMAGE_MAX_DIM), interpolation = cv2.INTER_AREA)\n",
    "                                train_images.append(resized)\n",
    "                                train_labels.append(0)\n",
    "                                falsecounter += 1\n",
    "                        else :\n",
    "                            bflag = 1\n",
    "                    if fflag == 1 and bflag == 1:\n",
    "                        print(\"inside\")\n",
    "                        flag = 1\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(\"error in \"+filename)\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4f3dfe-5922-40d3-8bd0-6658ca065a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = np.array(train_images)\n",
    "y_new = np.array(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71cc432-8cb9-4dcf-bb12-8a0966acd5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4589d703-4f22-4282-86f9-d7632850ecfb",
   "metadata": {},
   "source": [
    "# Model Formation and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90aca793-32ef-4d55-99e9-8bc017e498c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transfer learning from VGG16 model with imagenet weights.\n",
    "vggmodel = VGG16(weights=config.WEIGHTS , include_top=True)\n",
    "vggmodel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d254c15-08ae-44b9-a108-5abba6f0bcc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#freezing the first 15(index 0 to 14) layers in vggmodel\n",
    "for layers in (vggmodel.layers)[:15]:\n",
    "    print(layers)\n",
    "    layers.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a228d21f-75db-4c9c-b6df-5a5997b4e247",
   "metadata": {},
   "outputs": [],
   "source": [
    "vggmodel.layers[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e187756-7162-491b-9c6d-49e06c1f5ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = vggmodel.layers[-2].output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbff78f1-a4c4-4ddc-b3bf-fa3e5f6e26ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = Dense(2, activation=\"softmax\")(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda650ab-038a-460c-b313-a774b6f4e84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_final = Model(inputs = vggmodel.input, \n",
    "                    outputs = predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbff0a8c-1802-4f64-9030-1ad2d512baee",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Adam(learning_rate=config.LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41fb5911-c795-4ce5-b468-edaa0e0abb00",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_final.compile(loss = keras.losses.categorical_crossentropy, \n",
    "                    optimizer = opt, \n",
    "                    metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f629457d-405d-48f1-a497-3c792352d14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lenc = util.MyLabelBinarizer()\n",
    "Y =  lenc.fit_transform(y_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e747e9-060f-4731-b08f-a7eadaaec9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test , y_train, y_test = train_test_split(X_new,Y,test_size=0.10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f01279-c360-42ee-b018-e8805c6fa3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape,X_test.shape,y_train.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b214fb-0547-4d8b-82a0-383970d5821c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trdata = ImageDataGenerator(horizontal_flip=True, vertical_flip=True, rotation_range=config.ROTATION_RANGE_IMAGEGEN, dtype=config.DTYPE_IMAGEGEN)\n",
    "train_data = trdata.flow(x=X_train, y=y_train)\n",
    "tsdata = ImageDataGenerator(horizontal_flip=True, vertical_flip=True, rotation_range=config.ROTATION_RANGE_IMAGEGEN, dtype=config.DTYPE_IMAGEGEN)\n",
    "test_data = tsdata.flow(x=X_test, y=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab667c0-0607-4ed5-ba71-6a179cab06a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(\"exp1_rcnn_vgg16_1.h5\", monitor=config.MONITOR, verbose=1, save_best_only=True, save_weights_only=False, mode='auto', save_freq=config.SAVE_FREQ)\n",
    "early = EarlyStopping(monitor=config.MONITOR, min_delta=config.MIN_DELTA, patience=config.PATIENCE, verbose=1, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3fbda7b-452f-4050-ad03-933c37284419",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = model_final.fit(x= train_data, steps_per_epoch= config.STEPS_PER_EPOCH, epochs= config.TOTAL_EPOCHS, validation_data= test_data, validation_steps=config.VALIDATION_STEPS, callbacks=[checkpoint,early])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c750b52e-a26e-4b3d-8b4e-d8e5d982542b",
   "metadata": {},
   "source": [
    "# Visualization of Training Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1bae28-4d0f-42f2-857a-39a14b31c214",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(hist.history[\"acc\"])\n",
    "# plt.plot(hist.history['val_acc'])\n",
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.title(\"model loss\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.legend([\"Loss\",\"Validation Loss\"])\n",
    "plt.show()\n",
    "plt.savefig('chart loss.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564392da-dd4a-4e3b-b8ce-2e1593db71e3",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaae0bd6-80c6-46be-9aa7-1b7e4512b618",
   "metadata": {},
   "outputs": [],
   "source": [
    "im = X_test[15]\n",
    "plt.imshow(im)\n",
    "img = np.expand_dims(im, axis=0)\n",
    "out= model_final.predict(img)\n",
    "if out[0][0] > out[0][1]:\n",
    "    print(\"face\")\n",
    "else:\n",
    "    print(\"not face\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f181ef-4045-4dbe-9566-2f5982b4654e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#z=0\n",
    "#for e,i in enumerate(os.listdir(image_path)):\n",
    "    #if i.startswith(\"140\"):\n",
    "        #z += 1\n",
    "filename = '140.jpg'\n",
    "img = cv2.imread(os.path.join(image_path, filename))\n",
    "#ss.setBaseImage(img)\n",
    "#ss.switchToSelectiveSearchFast()\n",
    "#ssresults = ss.process()\n",
    "ssresults = selective_search(image_path, filename)\n",
    "imout = img.copy()\n",
    "for e,result in enumerate(ssresults):\n",
    "    if e < config.MAX_REGIONS:\n",
    "        x,y,w,h = result\n",
    "        timage = imout[y:y+h,x:x+w]\n",
    "        resized = cv2.resize(timage, (config.IMAGE_MIN_DIM, config.IMAGE_MAX_DIM), interpolation = cv2.INTER_AREA)\n",
    "        img = np.expand_dims(resized, axis=0)\n",
    "        out= model_final.predict(img)\n",
    "        if out[0][0] > 0.65:\n",
    "            cv2.rectangle(imout, (x, y), (x+w, y+h), (0, 255, 0), 1, cv2.LINE_AA)\n",
    "plt.figure()\n",
    "plt.imshow(imout)\n",
    "        #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67008994-5ac6-4327-acd6-c60ba5ab9976",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf_rcnn]",
   "language": "python",
   "name": "conda-env-tf_rcnn-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
